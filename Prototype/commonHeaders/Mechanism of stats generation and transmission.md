# Mechanism of statistics generation and transmission
### Generator and verifier
The generator and verifier components are the source of the statistics data and are considered the observable part of the system which acts as an indicator of the system behavior and the result of the tests executed by the admin client.<br>
There is a specific schema for the data produced by the two components. The generator is concerned about (Number of packets produced, Number of packets sent with errors). The verifier is concerned about (Number of packets received correctly, Number of erroneous packets, Number of packets not received, Number of packets received out of order).
<br>
Along each generator or verifier instance there exists a singleton entity called `statsManager` which is responsible for keeping track of the statistics data generated by this specific instance. During the processing of a packet, the packet is classified to be a member of one of the types of packets indicated by the schema (such as valid packet, out of order packet,... etc), and accordingly the counter of that type is increased showing that the a new packet of that type is processed. The counters in the `statsManager` are reset after each time the statistics are exported to start a new observing interval, which is one second (1000 ms) by default, but it can be changed without interfering with other components.
<br>
Each generator or verifier instance has a corresponding pipe to write the collected statistics on, which is read later by the kafka sub-module inside the system API. The pipes are named pipe (`FIFO`) that are stored in a specific directory on the machine running the components.

### System API
The system api has an integral role in this processes. It is responsible for:
* Locating the statistics data pipes
* Opening the pipes <br>
    preventing indefinite blocking of the statistics worker thread in generators and verifiers.
* Consuming data <br>
    There are two workers in the system API (corresponding to the types of managed instances ie. generators and verifiers). Each worker opens the pipes of the assigned type and consume the data and writes what it collected in the main thread of the statsManager in the systemAPI.
* Transmit the data <br>
    The aggregated data of all generators and all verifiers running on a specific machine is reconfigured and transformed into a data structure called `Topic` (with the help of `avro`) which is then used by the kafka broker sub-module to transmit statistics to the front-end of the application (namely the center point in the admin client).
